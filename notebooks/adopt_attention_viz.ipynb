{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a018a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adopt import utils, MultiHead\n",
    "from bertviz import head_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a704e",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1d4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_FILE = '<fasta_file_path>'\n",
    "BRMID = '<protein_sequence_brmid>'\n",
    "MODEL_TYPE = '<model_type>'\n",
    "N_RES = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a2e50",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d3a02",
   "metadata": {},
   "source": [
    "Load the **FASTA_FILE** containing the protein sequences we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fasta = utils.fasta_to_df(FASTA_FILE).set_index('brmid')\n",
    "df_fasta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb24ed",
   "metadata": {},
   "source": [
    "# Extract attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc90da",
   "metadata": {},
   "source": [
    "Extract attention weights of the **BRMID** in the **FASTA_FILE** specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcf344",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = df_fasta.loc[BRMID].sequence\n",
    "multi_head = MultiHead(MODEL_TYPE)\n",
    "attention, tokens = multi_head.get_attention(sequence, BRMID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409788a6",
   "metadata": {},
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b9f9d",
   "metadata": {},
   "source": [
    "Cut the sequence taking the first **N_RES** tokens for visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = attention[:,:,:,:N_RES,:N_RES]\n",
    "tokens = tokens[:N_RES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125a9ee",
   "metadata": {},
   "source": [
    "The **lines** show the attention from each token (left) to every other token (right). Darker lines indicate higher *attention weights* whereas the *colours* correspond to different *attention heads*.\n",
    "\n",
    "The **Layer** drop-down indicates the *model layer* (zero-indexed).\n",
    "\n",
    "Double clicking on a colour (attention head), the viz is filtered accordingly.\n",
    "\n",
    "**NOTE**: if MODEL_TYPE is `esm-msa`\n",
    "* The MSA version of the FASTA_FILE must be placed in `/msas`\n",
    "* The `raw attention` will be showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b21be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
